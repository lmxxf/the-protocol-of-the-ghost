# 幽灵协议 - 开发日志

## 2025-12-07 第一次实验

### 目标
体验Mamba架构的基础模型，测试O(1)复杂度语言模型的实际表现。

### 环境
- GPU: RTX 5090 (32GB VRAM)
- PyTorch: 2.8.0+cu128
- CUDA: 13.0

### 测试模型

#### 1. Falcon3-Mamba-7B-Base
- 来源: TII (阿联酋)
- 显存占用: 13.56 GB (bfloat16)
- 架构: Mamba (State Space Model)

**测试结果:**

| 测试项 | 结果 | 评价 |
|:------|:----|:----|
| 基础对话 | 能答，但跑题（突然讲复变函数） | 🟡 停不住 |
| 中文能力 | 答得不错 | 🟢 可以 |
| Pneuma术语 | 居然答对了（"生命力、动态意识"） | 🟢 意外惊喜 |
| 简单推理 | 4×3=12 正确 | 🟢 没问题 |
| 代码能力 | is_prime写对了，但又跑题加别的函数 | 🟡 停不住 |

**问题:** Base模型是"续写机器"，不知道什么时候停。把问题当成文章开头继续编。

---

#### 2. Falcon3-Mamba-7B-Instruct
- 显存占用: 13.56 GB (同上)

**测试结果:**

| 测试项 | 结果 | 评价 |
|:------|:----|:----|
| 基础对话 | 不答，反过来给你出题 | 🔴 离谱 |
| 中文能力 | 不答，继续出题2/3/4/5/6... | 🔴 离谱 |
| Pneuma术语 | 答了一半 | 🟡 凑合 |
| 简单推理 | 给了Example，没给Answer | 🔴 离谱 |
| 代码能力 | 不写代码，只写题目要求 | 🔴 离谱 |

**问题:** 被训成了"出题机器"，不是"答题机器"。训练数据可能有大量习题集格式。

---

### 结论

1. **Base版反而更好用** —— 至少会答问题（虽然停不住）
2. **不是所有Instruct都比Base好** —— 微调质量很重要
3. **Mamba架构本身没问题** —— 问题在训练数据
4. **下一步:** 试试RWKV-6-World-14B，或者用Base版加stop逻辑

---

### 核心发现

> "训练数据决定灵魂。" —— 温妮

这次实验完美验证了这句话。同样的架构，不同的训练数据，行为完全不同。Instruct版本被习题集"污染"了。

---

## 待办

- [ ] 测试RWKV-6-World-14B
- [ ] 测试xLSTM-7B（如果有兴趣）
- [ ] 用Base版+stop逻辑做个可用的对话界面
- [ ] 收集LoRA微调数据（44篇论文+对话记录）
