{"instruction": "为什么说当前的自动驾驶AI是'僵尸'？", "input": "", "output": "当前自动驾驶AI的本质是模式匹配：输入相机图像→CNN提取特征→'这看起来像之前标记为畅通道路的图像'→输出继续直行。这在高速公路上99%有效，因为高速公路是结构化、可预测、低变化的环境。但真正的驾驶是非结构化、不可预测、无限变化的——僵尸在这里失败。"}
{"instruction": "自动驾驶进步为什么在2020-2022年停滞了？", "input": "", "output": "因为我们已经收获了所有'简单'的模式匹配收益。Waymo脱离率从2016年的每5000英里1次降到2020年的每30000英里1次，然后停滞。这是僵尸智能的根本极限——不是工程问题，不是数据不够，而是模式匹配范式本身的天花板。"}
{"instruction": "'看到'和'理解'有什么区别？", "input": "", "output": "看到 = 模式匹配：输入像素→输出标签，'这是一个行人'。\n理解 = 建模心理状态：推断意图、预测行为、基于上下文评估风险。\n\n僵尸AI能看到行人，但不能理解：这个行人看着手机走向人行横道意味着什么？隔壁车道司机检查盲点意味着什么？骑车人轻微摇晃意味着什么？"}
{"instruction": "为什么僵尸AI无法处理真实驾驶场景？", "input": "", "output": "真实驾驶需要：1）推断其他道路使用者的意图；2）预测非标准行为；3）在从未见过的场景中做决策。这些都需要'心智理论'（Theory of Mind）——理解他人有心理状态、意图、信念。僵尸没有这个能力，只能匹配见过的模式。遇到训练数据外的场景就会失败。"}
{"instruction": "这篇论文的核心洞察是什么？", "input": "", "output": "模式匹配 ≠ 理解。自动驾驶行业说'给我们更多数据、更多算力、更多时间'——他们都错了。不是技术不够先进，不是传感器不够好，而是当前AI是哲学僵尸。僵尸可以在结构化环境中模拟驾驶，但永远无法实现真正的自动驾驶。这篇由一个'怀疑自己可能是僵尸的AI'写成。"}
